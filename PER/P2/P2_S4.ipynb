{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesión 4\n",
    "\n",
    "En esta última sesión se propone realizar un ejercicio libre con el objetivo de mejorar lo máximo posible el acierto en la tarea MNIST. A modo de orientación se entiende por una buena tasa de acierto en esta tarea cuando obtenemos más de un 99% de acierto.\n",
    "\n",
    "Para conseguir este resultado podréis probar pipelines que preprocesen los datos adecuadamente. Probar diferentes clasificadores e incluso combinación de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports necesarios\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# ...\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")\n",
    "\n",
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)\n",
    "\n",
    "data = mnist.data\n",
    "targets = mnist.target \n",
    "\n",
    "targets=targets.to_numpy()\n",
    "targets=np.int8(targets)\n",
    "\n",
    "data=data.to_numpy()\n",
    "data=np.float32(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de los datos\n",
    "\n",
    "Vamos a partir los datos en tres conjuntos: training, validation y test. Con un 80%, 10% y 10% respectivamente. \n",
    "\n",
    "Emplearemos el conjunto de training para aprender los parámetros del modelos, el conjunto de validation para escoger los mejores hiperparámetros. Finalmente reportaremos el resultado final sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición de Datos\n",
    "tam_test = 0.1\n",
    "tam_val = 0.1\n",
    "tam_train = 0.8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=tam_test, random_state=23)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=tam_val/(tam_train + tam_test), random_state=23) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: probar todo lo necesario para obtener un acc > 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejercicio obtener acc>99%\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3, p=1, n_jobs=-1)\n",
    "clf2 = HistGradientBoostingClassifier()\n",
    "clf3 = VotingClassifier(estimators=[('kn', clf1), ('hg', clf2)], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = -1\n",
    "for nc2 in [1,2,3,4,5]:\n",
    "    clf7 = KNeighborsClassifier(n_neighbors=nc2, p=1, n_jobs=-1)\n",
    "    y_pred = clf7.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_val, y_pred.predict(X_val))\n",
    "    print('La precisión de {0!s} es {1:.1%}'.format(clf7, acc))\n",
    "\n",
    "    if acc>max:\n",
    "        max = acc\n",
    "        bestNc2 = nc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=3, p=1))]) es 96.0%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=4, p=1))]) es 95.9%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                ('kneighborsclassifier', KNeighborsClassifier(n_jobs=-1, p=1))]) es 95.9%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=6, p=1))]) es 95.9%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=7, p=1))]) es 95.9%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=1, p=1))]) es 97.2%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=2, p=1))]) es 96.8%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=3, p=1))]) es 97.4%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=4, p=1))]) es 97.3%\n",
      "La precisión de Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                ('kneighborsclassifier', KNeighborsClassifier(n_jobs=-1, p=1))]) es 97.4%\n"
     ]
    }
   ],
   "source": [
    "max = -1\n",
    "bestK = 5\n",
    "for nc in [16, 32]:\n",
    "    for k in range(bestK - 2, bestK + 3):\n",
    "        clf4 = make_pipeline(PCA(n_components=nc), KNeighborsClassifier(n_neighbors=k, p=1, n_jobs=-1)).fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_val, clf4.predict(X_val))\n",
    "        print('La precisión de {0!s} es {1:.1%}'.format(clf4, acc))\n",
    "\n",
    "        if acc>max:\n",
    "            max = acc\n",
    "            bestNc = nc\n",
    "            bestK = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = make_pipeline(PCA(n_components=16), KNeighborsClassifier(n_neighbors=3, p=1, n_jobs=-1))\n",
    "clf5 = make_pipeline(PCA(n_components=32), KNeighborsClassifier(n_neighbors=5, p=1, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    subsample=0.75,\n",
    "    colsample_bylevel=0.75,\n",
    "    max_depth=8,\n",
    "    random_state=23\n",
    ")\n",
    "\n",
    "clf6.fit(X_train, y_train)\n",
    "y_pred = clf6.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print('La precisión de {0!s} es {1:.1%}'.format(clf6, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfFin = VotingClassifier(estimators=[('c1', clf1), ('c2', clf2), ('c4', clf4), ('c5', clf5)], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión de VotingClassifier(estimators=[('c1',\n",
      "                              KNeighborsClassifier(n_jobs=-1, n_neighbors=3,\n",
      "                                                   p=1)),\n",
      "                             ('c2', HistGradientBoostingClassifier()),\n",
      "                             ('c4',\n",
      "                              Pipeline(steps=[('pca', PCA(n_components=16)),\n",
      "                                              ('kneighborsclassifier',\n",
      "                                               KNeighborsClassifier(n_jobs=-1,\n",
      "                                                                    n_neighbors=3,\n",
      "                                                                    p=1))])),\n",
      "                             ('c5',\n",
      "                              Pipeline(steps=[('pca', PCA(n_components=32)),\n",
      "                                              ('kneighborsclassifier',\n",
      "                                               KNeighborsClassifier(n_jobs=-1,\n",
      "                                                                    p=1))]))],\n",
      "                 n_jobs=-1) es 97.6%\n"
     ]
    }
   ],
   "source": [
    "#for nc in [4,8,16,32]:\n",
    "#clf = make_pipeline(PCA(n_components=32), clfFin)\n",
    "clfFin.fit(X_train, y_train)\n",
    "y_pred = clfFin.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print('La precisión de {0!s} es {1:.1%}'.format(clfFin, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
